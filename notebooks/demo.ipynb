{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4580b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kpandit\\pyseq2500\\pyseq\\image_analysis.py:955: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  im = xr.open_zarr(fn).to_array()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageAnalysis::Opened m4 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'GFAP' at 0x1cc26d3bfd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpandit\\.conda\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "It 10 - total loss: 0.8100378513336182, total MI loss: 0.8099614381790161, total contrast loss: 7.64191136113368e-05\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "from skimage.data import astronaut\n",
    "from napari_picasso.main_widget import PicassoWidget\n",
    "from pyseq import image_analysis as ia\n",
    "\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.registration._phase_cross_correlation import _upsampled_dft\n",
    "from scipy.ndimage import fourier_shift\n",
    "import numpy as np\n",
    "\n",
    "#image_path = 'Z:\\\\gpfs\\\\commons\\\\groups\\\\nygcfaculty\\\\PySeq\\\\20210323_4i4color\\\\zarrs\\\\m4_o25933_labels.zarr'\n",
    "image_path = 'Z:\\\\gpfs\\\\commons\\\\groups\\\\nygcfaculty\\\\PySeq\\\\20210323_4i4color\\\\zarrs\\\\m4.zarr'\n",
    "o = 25933\n",
    "im = ia.get_HiSeqImages(image_path)\n",
    "cropped_im = im.im.sel(row = slice(3800,4000), col = slice(4100, 4300), cycle=5, obj_step=o)\n",
    "#cropped_im = im.im.sel(row = slice(1600,1600+256), col = slice(5000, 5000+256), cycle=5, obj_step=o)\n",
    "#cropped_im = im.im.sel(cycle=5, obj_step=o)\n",
    "\n",
    "\n",
    "# # subpixel registration\n",
    "# nuclei = cropped_im.sel(channel=558).compute()\n",
    "# gfap = cropped_im.sel(channel=610).compute()\n",
    "\n",
    "# # subpixel precision\n",
    "# shift, error, diffphase = phase_cross_correlation(gfap, nuclei, upsample_factor=100)\n",
    "\n",
    "\n",
    "# # The shift nuclei image\n",
    "# offset_image = fourier_shift(np.fft.fftn(nuclei), shift)\n",
    "# offset_image = np.fft.ifftn(offset_image)\n",
    "# nuclei_shifted = np.array(offset_image.real).clip(0,4095).astype('int16')\n",
    "\n",
    "\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "#widget = PicassoWidget(viewer)\n",
    "widget = PicassoWidget(viewer)\n",
    "viewer.window.add_dock_widget(widget)\n",
    "#viewer.add_image(astronaut(), channel_axis=-1)\n",
    "viewer.add_image(cropped_im.sel(channel=558), name='Laminin1b', blending = 'additive', contrast_limits = (0,4095))\n",
    "viewer.add_image(cropped_im.sel(channel=610), name='GFAP', blending = 'additive',  contrast_limits = (0,4095))\n",
    "# viewer.add_image(im.im.sel(obj_step = o, channel=687, cycle=5), name='MBP', blending = 'additive')\n",
    "# viewer.add_image(im.im.sel(obj_step = o, channel=740, cycle=5), name='ELAVL2', blending = 'additive')\n",
    "\n",
    "# viewer.add_image(nuclei_shifted, name='Laminin1b', blending = 'additive', contrast_limits = (0,4095))\n",
    "# viewer.add_image(gfap, name='GFAP', blending = 'additive',  contrast_limits = (0,4095))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cec58d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m widget\u001b[38;5;241m.\u001b[39msink_sources_match(widget\u001b[38;5;241m.\u001b[39mpicasso_params, widget\u001b[38;5;241m.\u001b[39mmixing_dict)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mwidget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msink_sources_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpicasso_params\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(widget\u001b[38;5;241m.\u001b[39msink_sources_dict(widget\u001b[38;5;241m.\u001b[39mmixing_dict))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mset\u001b[39m(widget\u001b[38;5;241m.\u001b[39mmixing_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGFAP\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32mc:\\users\\kpandit\\picasso\\src\\napari_picasso\\main_widget.py:169\u001b[0m, in \u001b[0;36mPicassoWidget.sink_sources_dict\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    167\u001b[0m         sink \u001b[38;5;241m=\u001b[39m images[parameters[\u001b[38;5;241m0\u001b[39m,:,col] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    168\u001b[0m         sources \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(images[parameters[\u001b[38;5;241m0\u001b[39m,:,col] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m--> 169\u001b[0m         ss_dict[sink] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(sources)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ss_dict\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "widget.sink_sources_match(widget.picasso_params, widget.mixing_dict)\n",
    "print(widget.sink_sources_dict(widget.picasso_params))\n",
    "print(widget.sink_sources_dict(widget.mixing_dict))\n",
    "set(widget.mixing_dict['GFAP'].keys())\n",
    "widget.picasso_params[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ff84b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m test \u001b[38;5;241m=\u001b[39m widget\u001b[38;5;241m.\u001b[39m_options\u001b[38;5;241m.\u001b[39mupdate({})\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "test = widget._options.update({})\n",
    "test.get('max_iter',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae60968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.utils.notifications import show_info\n",
    "show_info('Hello Napari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4b8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_info('Hello Napari')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ed0764",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpandit\\.conda\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\users\\kpandit\\pyseq2500\\pyseq\\image_analysis.py:955: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  im = xr.open_zarr(fn).to_array()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageAnalysis::Opened m4 \n",
      "reserved_memory :: 0 B\n",
      "free_memory :: 0 B\n",
      "Using cuda\n",
      "reserved_memory :: 2.00 MiB\n",
      "free_memory :: 1.99 MiB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dask.utils import format_bytes\n",
    "from picasso.nn_picasso import PICASSOnn\n",
    "from pyseq import image_analysis as ia\n",
    "\n",
    "\n",
    "image_path = 'Z:\\\\gpfs\\\\commons\\\\groups\\\\nygcfaculty\\\\PySeq\\\\20210323_4i4color\\\\zarrs\\\\m4.zarr'\n",
    "im = ia.get_HiSeqImages(image_path)\n",
    "o = 25933\n",
    "mixed_im = im.im.sel(cycle=5, obj_step=o)\n",
    "\n",
    "def report_mem():\n",
    "    reserve_mem = torch.cuda.memory_reserved()\n",
    "    free_mem = torch.cuda.memory_reserved() - torch.cuda.memory_allocated()\n",
    "    print('reserved_memory','::',format_bytes(reserve_mem))\n",
    "    print('free_memory','::',format_bytes(free_mem))\n",
    "    \n",
    "report_mem()\n",
    "mm = np.array([[1],[-1],[-1],[-1]])\n",
    "model = PICASSOnn(mm)\n",
    "report_mem()\n",
    "# dataset = model.get_dataset(mixed_im.sel(channel=[558, 610]))\n",
    "# report_mem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f822f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log, floor\n",
    "\n",
    "2**floor(log(torch.cuda.get_device_properties('cuda').total_memory/8000,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a3363a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reserved_memory :: 2.00 MiB\n",
      "free_memory :: 1.99 MiB\n"
     ]
    }
   ],
   "source": [
    "dataset = model.get_dataset(mixed_im)\n",
    "report_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e546a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dask.array as da\n",
    "\n",
    "DA_TYPE = type(da.zeros(0))\n",
    "TT_TYPE = type(torch.tensor(0))\n",
    "# def collate(chunk_, dtype = torch.float32):\n",
    "\n",
    "#     _type = type(chunk_)\n",
    "\n",
    "#     assert _type in [DA_TYPE, list], f'Expected dask array or list, got {_type}'\n",
    "#     if _type is list:\n",
    "#         assert isinstance(chunk_[0], DA_TYPE)\n",
    "#         chunk_ = chunk_[0]\n",
    "\n",
    "#     #chunk = torch.tensor(chunk_.compute(), dtype=dtype, device = 'cuda')\n",
    "#     #chunk = chunk.compute()\n",
    "    \n",
    "#     worker_info = torch.utils.data.get_worker_info()\n",
    "#     if worker_info is None:\n",
    "#         return iter([None]*3)\n",
    "#     else:\n",
    "#     # in a worker process\n",
    "#     # split workload\n",
    "#         worker_id = worker_info.id\n",
    "#         return iter([worker_id]*3)\n",
    "\n",
    "def collate(chunk_, dtype = torch.float32):\n",
    "    \n",
    "    device = 'cuda'\n",
    "    iscuda = device == 'cuda'\n",
    "\n",
    "    _type = type(chunk_)\n",
    "\n",
    "    assert _type in [DA_TYPE, TT_TYPE, list], f'Expected dask array or list, got {_type}'\n",
    "    if _type is list:\n",
    "        _type = type(chunk_[0])\n",
    "        assert _type in [DA_TYPE, TT_TYPE]\n",
    "        chunk_ = chunk_[0]\n",
    "\n",
    "    if _type is TT_TYPE:\n",
    "        if chunk_.device.type != device:\n",
    "            chunk_ = chunk_.to(device, non_blocking = iscuda)\n",
    "        return chunk_\n",
    "    else:\n",
    "        return torch.tensor(chunk_.compute(), dtype=dtype, device=device)\n",
    "    \n",
    "\n",
    "    #return chunk\n",
    "    \n",
    "dataloader = DataLoader(dataset, shuffle=True, collate_fn = collate)\n",
    "\n",
    "for i, im in enumerate(dataloader):\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1a09e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n"
     ]
    }
   ],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a4e24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrain_loop(mixed_im)\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m report_mem()\n",
      "File \u001b[1;32mc:\\users\\kpandit\\picasso\\src\\picasso\\nn_picasso.py:199\u001b[0m, in \u001b[0;36mPICASSOnn.train_loop\u001b[1;34m(self, images, max_iter, batch_size, lr, opt, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)                                 \u001b[38;5;66;03m# per documentation saves memory\u001b[39;00m\n\u001b[0;32m    198\u001b[0m total_loss, mi_loss, contrast_loss  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(ims)\n\u001b[1;32m--> 199\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Save mixing parameters over iterations\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAVE_MIX_PARAMETERS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cuda\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_gen = model.train_loop(mixed_im)\n",
    "next(train_gen)\n",
    "report_mem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a960261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.from_numpy(np.array(0))\n",
    "test = test.pin_memory()\n",
    "test.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bff9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_tensor = torch.tensor(cropped_im.sel(channel=558).data.astype('int16').compute(), device = 'cpu')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c99d320",
   "metadata": {},
   "source": [
    "test = da_tensor.pin_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9146ef4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe156d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([18749440, 2])\n",
      "1 torch.Size([18831360, 2])\n",
      "2 torch.Size([18831360, 2])\n",
      "3 torch.Size([18831360, 2])\n",
      "4 torch.Size([18831360, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dask.array as da\n",
    "\n",
    "\n",
    "DA_TYPE = type(da.zeros(0))\n",
    "def dask_collate(chunk_, dtype = torch.float32):\n",
    "\n",
    "    _type = type(chunk_)\n",
    "\n",
    "    assert _type in [DA_TYPE, list], f'Expected dask array or list, got {_type}'\n",
    "    if _type is list:\n",
    "        assert isinstance(chunk_[0], DA_TYPE)\n",
    "        chunk_ = chunk_[0]\n",
    "        \n",
    "    chunk = torch.tensor(chunk_.compute(), dtype=dtype, device = 'cuda')\n",
    "\n",
    "\n",
    "    return chunk\n",
    "\n",
    "dataloader = DataLoader(dataset, shuffle=True, collate_fn = dask_collate)\n",
    "\n",
    "for batch, im_list in enumerate(dataloader):\n",
    "    print(batch, im_list.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1539cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reserved_memory :: 1.27 GiB\n",
      "free_memory :: 1.99 MiB\n"
     ]
    }
   ],
   "source": [
    "report_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d04a714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94074880"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9236e394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kpandit\\.conda\\envs\\cuda\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'im' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved())\n\u001b[0;32m      5\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_properties(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m mixed_im \u001b[38;5;241m=\u001b[39m \u001b[43mim\u001b[49m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39msel(cycle\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, obj_step\u001b[38;5;241m=\u001b[39mo)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreport_mem\u001b[39m(step):\n\u001b[0;32m      9\u001b[0m     free_mem \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_reserved() \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'im' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dask.utils import format_bytes\n",
    "torch.cuda.memory_reserved() - torch.cuda.memory_allocated()\n",
    "print(torch.cuda.memory_reserved())\n",
    "torch.cuda.get_device_properties('cuda')\n",
    "mixed_im = im.im.sel(cycle=5, obj_step=o)\n",
    "\n",
    "def report_mem(step):\n",
    "    free_mem = torch.cuda.memory_reserved() - torch.cuda.memory_allocated()\n",
    "    print(step,'::',format_bytes(free_mem))\n",
    "    \n",
    "report_mem('initializing cuda')\n",
    "mm = np.array([[1],[-1]])\n",
    "model = PICASSOnn(mm)\n",
    "report_mem('creating model')\n",
    "dataset = model.get_dataset(mixed_im.sel(channel=[558, 610]))\n",
    "report_mem('creating dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c8efbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, l in enumerate(viewer.layers):\n",
    "    if l.name == 'unmixed_GFAP':\n",
    "        print(i)\n",
    "        break\n",
    "    \n",
    "viewer.layers[i].data = np.ones_like(viewer.layers[i].data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2a36b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.ones_like(viewer.layers[i].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e1fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "import numpy as np\n",
    "from napari_picasso.main_widget import PicassoWidget\n",
    "\n",
    "\n",
    "# Make sink source images\n",
    "s = 512; background = 100; signal = 500; alpha = 0.5\n",
    "\n",
    "sink = np.random.rand(s,s)*10+background\n",
    "sink[:100, :100] += np.random.rand(100,100)*2000+signal\n",
    "\n",
    "source = np.zeros((s,s))\n",
    "source[-100:,-100:] += np.random.rand(100,100)*2000+signal\n",
    "\n",
    "sink += alpha*source\n",
    "source += np.random.rand(s,s)*10+background\n",
    "\n",
    "# Add to viewer\n",
    "viewer = napari.Viewer(show=False)\n",
    "viewer.add_image(sink, name='sink')\n",
    "viewer.add_image(source, name='source')\n",
    "\n",
    "# setup widget\n",
    "widget = PicassoWidget(viewer)\n",
    "widget.add_sink_widget()\n",
    "\n",
    "sink = widget['sink0']\n",
    "sink.sink_list.bind(sink)\n",
    "sink.show_sources()\n",
    "sink.update_mixing_params()\n",
    "\n",
    "for s in widget.sinks:\n",
    "    sink = widget[f'sink{s}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95009e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from magicgui.widgets import RadioButtons, Container, CheckBox\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310d920",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
