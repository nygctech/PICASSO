{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63f6bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mine' from 'C:\\\\Users\\\\kpandit\\\\PICASSO\\\\picasso\\\\mine.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\kpandit\\\\PICASSO\\\\picasso\\\\')\n",
    "import mine\n",
    "importlib.reload(mine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "def9eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageAnalysis::Opened m4 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2 {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;m4&#x27; (channel: 4, row: 256, col: 256)&gt;\n",
       "dask.array&lt;getitem, shape=(4, 256, 256), dtype=uint16, chunksize=(1, 256, 256), chunktype=numpy.ndarray&gt;\n",
       "Coordinates:\n",
       "  * channel   (channel) int64 558 610 687 740\n",
       "    cycle     int64 5\n",
       "    obj_step  int64 25228\n",
       "Dimensions without coordinates: row, col\n",
       "Attributes:\n",
       "    first_group:  0\n",
       "    machine:      None\n",
       "    scale:        1\n",
       "    fixed_bg:     0</pre><div class='xr-wrap' hidden><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'m4'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>channel</span>: 4</li><li><span>row</span>: 256</li><li><span>col</span>: 256</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-15ed7404-b950-40ff-9c02-5cfc62d7e6bc' class='xr-array-in' type='checkbox' checked><label for='section-15ed7404-b950-40ff-9c02-5cfc62d7e6bc' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>dask.array&lt;chunksize=(1, 256, 256), meta=np.ndarray&gt;</span></div><div class='xr-array-data'><table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 512.00 kiB </td>\n",
       "                        <td> 128.00 kiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (4, 256, 256) </td>\n",
       "                        <td> (1, 256, 256) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3005 Tasks </td>\n",
       "                        <td> 4 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint16 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"196\" height=\"186\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"120\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"14\" y2=\"124\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"18\" y2=\"128\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"132\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 26.279639528180862,16.279639528180862 26.279639528180862,136.27963952818087 10.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"14\" y1=\"4\" x2=\"134\" y2=\"4\" />\n",
       "  <line x1=\"18\" y1=\"8\" x2=\"138\" y2=\"8\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"26\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 146.27963952818087,16.279639528180862 26.279639528180862,16.279639528180862\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"26\" y1=\"136\" x2=\"146\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"146\" y1=\"16\" x2=\"146\" y2=\"136\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"26.279639528180862,16.279639528180862 146.27963952818087,16.279639528180862 146.27963952818087,136.27963952818087 26.279639528180862,136.27963952818087\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"86.279640\" y=\"156.279640\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >256</text>\n",
       "  <text x=\"166.279640\" y=\"76.279640\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,166.279640,76.279640)\">256</text>\n",
       "  <text x=\"8.139820\" y=\"148.139820\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,8.139820,148.139820)\">4</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table></div></div></li><li class='xr-section-item'><input id='section-355ea3c3-8c38-48bd-8a5e-7a900ec1b79e' class='xr-section-summary-in' type='checkbox'  checked><label for='section-355ea3c3-8c38-48bd-8a5e-7a900ec1b79e' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>channel</span></div><div class='xr-var-dims'>(channel)</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>558 610 687 740</div><input id='attrs-c5f4bea2-335a-4229-8cd8-48817ea8ea5f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c5f4bea2-335a-4229-8cd8-48817ea8ea5f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-27b96527-c17f-42bd-9e4e-8af686c06d61' class='xr-var-data-in' type='checkbox'><label for='data-27b96527-c17f-42bd-9e4e-8af686c06d61' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([558, 610, 687, 740], dtype=int64)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>cycle</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>5</div><input id='attrs-86519007-a722-4dca-80b5-9b26a1918388' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-86519007-a722-4dca-80b5-9b26a1918388' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-841303c6-f374-40da-bc25-4173cbc4f294' class='xr-var-data-in' type='checkbox'><label for='data-841303c6-f374-40da-bc25-4173cbc4f294' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(5, dtype=int64)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>obj_step</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int64</div><div class='xr-var-preview xr-preview'>25228</div><input id='attrs-c35395be-900e-4c42-9e64-33e3a52d2801' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c35395be-900e-4c42-9e64-33e3a52d2801' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a787187a-a6ca-4d8e-8f56-6cb06a59c1cb' class='xr-var-data-in' type='checkbox'><label for='data-a787187a-a6ca-4d8e-8f56-6cb06a59c1cb' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array(25228, dtype=int64)</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-366588ad-25e9-4d24-9e9b-110a0c126ffe' class='xr-section-summary-in' type='checkbox'  checked><label for='section-366588ad-25e9-4d24-9e9b-110a0c126ffe' class='xr-section-summary' >Attributes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>first_group :</span></dt><dd>0</dd><dt><span>machine :</span></dt><dd>None</dd><dt><span>scale :</span></dt><dd>1</dd><dt><span>fixed_bg :</span></dt><dd>0</dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'm4' (channel: 4, row: 256, col: 256)>\n",
       "dask.array<getitem, shape=(4, 256, 256), dtype=uint16, chunksize=(1, 256, 256), chunktype=numpy.ndarray>\n",
       "Coordinates:\n",
       "  * channel   (channel) int64 558 610 687 740\n",
       "    cycle     int64 5\n",
       "    obj_step  int64 25228\n",
       "Dimensions without coordinates: row, col\n",
       "Attributes:\n",
       "    first_group:  0\n",
       "    machine:      None\n",
       "    scale:        1\n",
       "    fixed_bg:     0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyseq import image_analysis as ia\n",
    "\n",
    "image_path = 'Y:\\\\Kunal\\\\HiSeqExperiments\\\\20210323_4i4color\\\\zarrs'\n",
    "im = ia.get_HiSeqImages(image_path)\n",
    "im.im\n",
    "opt_obj_step = im.im.obj_step[1]\n",
    "roi_center = (5594, 3548) # row, col\n",
    "roi_size = 256\n",
    "rows = slice(int(roi_center[0]-roi_size/2), int(roi_center[0]+roi_size/2))\n",
    "cols = slice(int(roi_center[1]-roi_size/2), int(roi_center[1]+roi_size/2))\n",
    "#im.show(selection = {'row':rows, 'col':cols, 'obj_step':25228})\n",
    "test_image = im.im.sel(row = rows, col = cols, obj_step = opt_obj_step, cycle = 5)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adbe5b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class PICASSOnn(nn.Module):\n",
    "    def __init__(self, mixing_matrix, \n",
    "                 transform: Union[None, nn.Module] = None, \n",
    "                 background: bool = True, \n",
    "                 px_bit_depth: int = 12, \n",
    "                 mi_weight: float  = 1.0, \n",
    "                 contrast_weight: float = 1.0):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        \n",
    "        self.mixing_matrix = torch.tensor(mixing_matrix, device = self.device)\n",
    "        # Pairs property take mixing matrix as input to set\n",
    "        self.pairs = self.mixing_matrix \n",
    "        \n",
    "        self.bit_depth = px_bit_depth\n",
    "        self.max_px = 2**px_bit_depth-1\n",
    "\n",
    "        self.clip = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
    "        if transform is None:\n",
    "            self.transform = MixModel(self.n_images, self.n_sinks, self.mixing_matrix, background)\n",
    "        else:\n",
    "            self.transform = transform\n",
    "        self.transform.to(self.device)\n",
    "        \n",
    "        \n",
    "        self.mine_ = []\n",
    "        for i in range(self.n_pairs):\n",
    "            self.mine_.append(mine.MINE())\n",
    "        self.mi_loss = torch.zeros((self.n_pairs,), requires_grad = False, device = self.device)\n",
    "            \n",
    "        self.mi_weight = mi_weight\n",
    "        self.contrast_weight = contrast_weight\n",
    "\n",
    "        \n",
    "        \n",
    "    def contrast_loss(self, x, y, k2 = 0.03):\n",
    "        \n",
    "        c2 = (1*k2)**2\n",
    "        varx = torch.var(x, dim = 0)\n",
    "        vary = torch.var(y, dim = 0)\n",
    "        score = (2*varx**0.5*vary**0.5+c2)/(varx+vary+c2)\n",
    "        \n",
    "        score = 1-score #keep contrast similiar\n",
    "        \n",
    "        return score\n",
    "\n",
    "    \n",
    "    def forward(self, images):\n",
    "        ''' images NxC: N = number of px, C = number of channels'''\n",
    "        \n",
    "        images = images/self.max_px\n",
    "\n",
    "        # Remove spillover spectras in sink images\n",
    "        no_spill = self.transform(images)\n",
    "              \n",
    "        # Keep contrast of sink image the same\n",
    "        contrast_loss = self.contrast_loss(images[:,self.sink_ind], no_spill)*self.contrast_weight\n",
    "        \n",
    "        # Minimize mutual information between cleaned sink image and source images\n",
    "        mi_loss = torch.tensor(0)\n",
    "        for i, (snk, src) in enumerate(self.pairs):\n",
    "            xy = torch.stack([no_spill[:,snk], images[:,src]], 1)\n",
    "            mi = (1-self.mine_[i].forward(xy))*self.mi_weight\n",
    "            self.mi_loss[i] = mi\n",
    "            mi_loss = mi_loss + mi\n",
    "            \n",
    "        total_loss = mi_loss + torch.sum(contrast_loss)\n",
    "\n",
    "        \n",
    "        # adaptive gradient clipping\n",
    "        #scale = torch.stack([mi_loss, ce_loss1]).abs().min()/mi_loss.abs()\n",
    "#         if mi_loss.abs() > contrast_loss.abs():\n",
    "#             scale = contrast_loss/mi_loss\n",
    "#             mi_loss = mi_loss*scale.abs()\n",
    "#         else:\n",
    "#             scale = mi_loss/contrast_loss\n",
    "#             contrast_loss = contrast_loss*scale.abs()\n",
    "        #contrast_loss = contrast_loss - 1\n",
    "        \n",
    "        return total_loss, self.mi_loss, contrast_loss\n",
    "    \n",
    "    \n",
    "#     def constrain_parameters(self, module: str = 'transform', \n",
    "#                                    min_mix: float = 0.01, max_mix: float = 2.0, \n",
    "#                                    bg_max: float = 0.1) -> None:\n",
    "        \n",
    "#         '''Constrain mixing model parameters.\n",
    "        \n",
    "#            Sink imaged weights and bias constrained to 1 and 0 respectively.\n",
    "#            Non interacting image weights and bias constrained to 0. \n",
    "        \n",
    "#         '''\n",
    "        \n",
    "#         if module in self._modules:\n",
    "#             w = self._modules[module].weight.data\n",
    "#             w = w.clamp(min_mix, max_mix)\n",
    "#             w[self._mixing_matrix == 1] = 1\n",
    "#             w[self._mixing_matrix == 0] = 0\n",
    "#             self._modules[module].weight.data = w\n",
    "            \n",
    "#             b = self._modules[module].bias\n",
    "#             if b is not None:\n",
    "#                 b = b.data.clamp(-bg_max, 0.0)\n",
    "#                 b[self._mixing_matrix == 1] = 0\n",
    "#                 b[self._mixing_matrix == 0] = 0\n",
    "#                 self._modules[module].bias.data = b\n",
    "                \n",
    "#         else:\n",
    "#             print(f'{module} not in model')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def train_loop(self, images, max_iter=40, batch_size=1, lr=1e-4, opt=None):\n",
    "       \n",
    "       \n",
    "        transform_params = [*self.transform.parameters()]\n",
    "                \n",
    "        mine_params = []    \n",
    "        for module in self.mine_:\n",
    "            for param in module.parameters():\n",
    "                mine_params.append(param)\n",
    "\n",
    "    \n",
    "        if opt is None:\n",
    "            opt = torch.optim.Adam([{'params':mine_params}, {'params':transform_params}], lr=lr)\n",
    "            opt.param_groups[0]['lr'] = lr/10 # Mine params learn 1/10 slower\n",
    "         \n",
    "        mix_params_ = []\n",
    "        mi_loss_ = []\n",
    "        contrast_loss_ = []\n",
    "        old_param = 0\n",
    "        \n",
    "        dataset = self.get_dataset(images)\n",
    "        \n",
    "        for i in range(1, max_iter + 1):\n",
    "\n",
    "            batch_loss = 0; batch_mi_loss = 0; batch_contrast_loss = 0\n",
    "            # CHANGE BATCHSIZE FROM 256\n",
    "            for batch, im in enumerate(DataLoader(dataset, 256, shuffle=True)):\n",
    "                \n",
    "                im = torch.tensor(im, device=self.device, requires_grad = False)\n",
    "                \n",
    "                opt.zero_grad()\n",
    "                total_loss, mi_loss, contrast_loss  = self.forward(im)\n",
    "                total_loss.backward()\n",
    "                ap = self.transform.get_parameters()\n",
    "                an = ap.norm()\n",
    "                tn = nn.utils.clip_grad_norm_(mine_params, an)\n",
    "                opt.step()\n",
    "                self.transform.constrain()\n",
    "                \n",
    "                batch_loss += total_loss.item()\n",
    "                batch_mi_loss += torch.sum(mi_loss)\n",
    "                batch_contrast_loss += torch.sum(contrast_loss)\n",
    "\n",
    "                # Save mixing parameters over iterations\n",
    "                mix_params_.append(self.transform.parameters())\n",
    "                    \n",
    "                # Save losses over iterations\n",
    "                mi_loss_.append(mi_loss)\n",
    "                contrast_loss_.append(contrast_loss)\n",
    "\n",
    "\n",
    "            loss_ = torch.tensor([batch_loss, batch_mi_loss, batch_contrast_loss])\n",
    "            loss_ /= batch\n",
    "            if i % (max_iter // 10) == 0:\n",
    "                print(ap)\n",
    "                print(f'It {i} - total norm: {tn}, alpha norm: {an}')\n",
    "                print(f\"It {i} - total loss: {loss_[0]}, total MI loss: {loss_[1]}, total contrast loss: {loss_[2]}\")\n",
    "                \n",
    "            # TODO: Convergence of mixing parameters\n",
    "#             new_param = self.flatten_parameters()\n",
    "#             param_norm = torch.linalg.norm(new_param - old_param)\n",
    "#             old_param = new_param                \n",
    "#             if param_norm.item() < 0.05:\n",
    "#                 print(f\"Converged in {i} iterations\")\n",
    "#                 break\n",
    "\n",
    "\n",
    "        train_info = {'mixing parameters': mix_params_,\n",
    "                      'mutual information loss': mi_loss_,\n",
    "                      'contrast loss': contrast_loss_}\n",
    "            \n",
    "        return train_info\n",
    "    \n",
    "    def get_dataset(self, images:tuple):\n",
    "        \n",
    "        assert len(images) == self.n_images, f'Expecting {self.n_images} images, got {shape[0]} images'\n",
    "        \n",
    "        ims = []\n",
    "        for i in images:\n",
    "            assert i.ndim == 2, f'Expecting 2D image'\n",
    "            if isinstance(i, type(np.zeros(0))):\n",
    "                ims.append(da.from_array(i).flatten())\n",
    "            elif isinstance(i, type(da.zeros(0))):\n",
    "                ims.append(i.flatten().compute())\n",
    "            # TODO what type are napari arrays?\n",
    "            else:\n",
    "                raise f'Expecting numpy or dask array'\n",
    "                \n",
    "                \n",
    "        return np.stack(ims, axis=1).astype('int16')\n",
    "            \n",
    "#         return da.map_blocks(torch.Tensor, da.stack(ims, axis=1))\n",
    "\n",
    "    \n",
    "#     def mix_parameters(self):\n",
    "#         '''Get model mixing parameters.'''\n",
    "        \n",
    "#         alpha = self.transform.alpha\n",
    "#         if self.bias:\n",
    "#             background = self._modules['transform'][0].background\n",
    "#             return alpha, background\n",
    "#         else:\n",
    "#             return alpha\n",
    "        \n",
    "#     def _unmix_images(self, images):\n",
    "                \n",
    "            \n",
    "#         # transform source images into sink channels\n",
    "#         transformed = self.transform(images[:,self.source_ind])\n",
    "        \n",
    "#         # Remove spillover\n",
    "        \n",
    "#         for snk, src, tfm in self.pairs:\n",
    "#             images[:,snk] = self.clip(images[:,snk]-transformed[:,tfm]) # clips values btwn 0.0 and 1.0\n",
    "                    \n",
    "#         return images\n",
    "    \n",
    "    def unmix_images(self, images, batch_size: int = 1):\n",
    "        \n",
    "        dataset = images.flatten(dim = (-1, -2))\n",
    "        \n",
    "        batches = []\n",
    "        for batch, images in enumerate(DataLoader(dataset, batch_size)):\n",
    "            unmixed_batch = self.transform(images)\n",
    "            batches.append(da.Array(unmixed_batch.detach().cpu()))\n",
    "        unmixed_ims = da.vstack(batches)\n",
    "        unmixed_ims = unmixed_ims.reshape(n_ims, h, w)\n",
    "        \n",
    "        return unmixed_ims\n",
    "              \n",
    "        \n",
    "    @property\n",
    "    def pairs(self):\n",
    "        return self._pairs\n",
    "    \n",
    "    @pairs.setter\n",
    "    def pairs(self, mixing_matrix):\n",
    "        '''Set list of pairs (sink index, source index).'''\n",
    "    \n",
    "        images, sinks = self._mixing_matrix.shape\n",
    "        \n",
    "        self._pairs = []\n",
    "        for i in range(images):\n",
    "            for ii in range(sinks):\n",
    "                if self.mixing_matrix[i,ii] == -1:\n",
    "                    self._pairs.append((ii, i))\n",
    "                    \n",
    "        self.n_pairs = len(self._pairs)\n",
    "    \n",
    "    @property\n",
    "    def mixing_matrix(self):\n",
    "        return self._mixing_matrix\n",
    "    \n",
    "    @mixing_matrix.setter\n",
    "    def mixing_matrix(self, mm):\n",
    "        '''Check and set the mixing matrix.\n",
    "        \n",
    "           rows = all images\n",
    "           cols = unmixed images\n",
    "           \n",
    "           Mark a sink image with a 1, only 1 sink image per column.\n",
    "           Mark a source image with a -1\n",
    "           All other images should be 0.\n",
    "           \n",
    "        '''\n",
    "        \n",
    "        n_src, n_snk = mm.shape\n",
    "        assert n_snk >= n_src, f'Number of sinks {n_snk} must be >= number of sources {n_src}'\n",
    "        if n_src == n_snk:\n",
    "            assert (mm.diagonal() == 1).all(), f'Diagonal of mixing matrix should be 1s'\n",
    "            off_diag = mm[~torch.eye(mm.shape[0],dtype=bool)] \n",
    "            assert ((off_diag==0) | (off_diag==-1)).all(), f'Off diagonal of mixing matrix should be -1s or 0s'\n",
    "        else:\n",
    "            assert ((mm==0) | (mm==-1) | (mm==1)).all(), f'Mixing matrix should only include -1s, 0s, or 1s'\n",
    "        \n",
    "        assert (mm==1).sum(axis=1).all() <= 1, f'Only 1 image can be marked as a sink per column in the mixing matrix'\n",
    "            \n",
    "        # Remove unused sources\n",
    "        mm = mm[~((mm==0).sum(dim=0) == n_snk)]\n",
    "        # Remove unused sinks\n",
    "        mm = mm[~((mm==0).sum(dim=1) == n_src)]\n",
    "        \n",
    "        self.source_ind = ~(mm.sum(dim=1) == 1)\n",
    "        self.sink_ind = (mm==-1).sum(dim=0) >= 1\n",
    "        \n",
    "        # Get images x sink mixing matrix (columns have 1 sink and at least one source image)\n",
    "        self._mixing_matrix = mm[:, self.sink_ind]\n",
    "        self.n_images, self.n_sinks = self._mixing_matrix.shape\n",
    "    \n",
    "        \n",
    "                \n",
    "class MixModel(nn.Module):\n",
    "    def __init__(self, images:int, sinks:int, mixing_matrix, background: bool = True, \n",
    "                 min_alpha:float = 0.01, max_alpha:float = 2.0, max_background:float = 0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert (images, sinks) == mixing_matrix.shape, f'Mixing matrix rows should = images, and cols should = sinks'\n",
    "        \n",
    "        self.mixing_matrix = mixing_matrix\n",
    "        self.bg = background\n",
    "        self.min_alpha = min_alpha\n",
    "        self.max_alpha = max_alpha\n",
    "        self.max_background = max_background\n",
    "        self.images = images\n",
    "        self.sinks = sinks\n",
    "        \n",
    "        self.Hardtanh = nn.Hardtanh(min_val=0.0, max_val=1.0)\n",
    "        \n",
    "        self.alpha = nn.Parameter(torch.ones((images, sinks), dtype=torch.float32)*0.1)\n",
    "        \n",
    "        if background:\n",
    "            self.background = nn.Parameter(torch.zeros((images, sinks), dtype=torch.float32))\n",
    "            \n",
    "        self.constrain()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 2, f'Got {x.ndim}D matrix, expected 2D matrix of flattened images, rows = px, cols = images'\n",
    "        px, images = x.shape\n",
    "        \n",
    "        assert images == self.images, f'Expected {self.images} images, got {images}'\n",
    "        \n",
    "        y = torch.zeros((px, self.sinks), dtype = torch.float32)\n",
    "        if self.bg:\n",
    "            for i in range(self.sinks):\n",
    "                y[:,i] = self.Hardtanh(x-self.background[:,i].T) @ (self.alpha[:,i]*self.mixing_matrix[:,i])\n",
    "        else:\n",
    "            y = x @ (self.alpha*self.mixing_matrix)\n",
    "\n",
    "            \n",
    "        return y\n",
    "        \n",
    "    def constrain(self):\n",
    "        \n",
    "        alpha = self.alpha.data\n",
    "        alpha = alpha.clamp(self.min_alpha, self.max_alpha)\n",
    "        alpha[self.mixing_matrix == 1] = 1\n",
    "        alpha[self.mixing_matrix == 0] = 0\n",
    "        self.alpha.data = alpha\n",
    "        \n",
    "        if self.bg:\n",
    "            background = self.background.data\n",
    "            background = background.clamp(0.0, self.max_background)\n",
    "            background[(self.mixing_matrix == 1) | (self.mixing_matrix == 0)] = 0.0\n",
    "            self.background.data = background\n",
    "        \n",
    "    def get_parameters(self):\n",
    "\n",
    "        params = []\n",
    "        for i in range(self.images):\n",
    "            for ii in range(self.sinks):\n",
    "                if self.mixing_matrix[i,ii] == -1:\n",
    "                    params.append([self.alpha[i,ii], self.background[i,ii]])\n",
    "                    \n",
    "        return torch.tensor(params)\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baa42b98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros() received an invalid combination of arguments - got (tuple, torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-a328926621a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m                  [0, 0, 0, 1]]# sink 740, spillover from 687\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpicasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPICASSOnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixing_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpicasso\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4095\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-163f449ff000>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mixing_matrix, transform, background, px_bit_depth, mi_weight, contrast_weight)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHardtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMixModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_sinks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmixing_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-163f449ff000>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, images, sinks, mixing_matrix, background, min_alpha, max_alpha, max_background)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbackground\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackground\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (tuple, torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "# Mixing matrix, rows are all images, cols are unmixed images\n",
    "# Mark sink as 1 in unmixed image\n",
    "# Mark sources as -1 unmixed image\n",
    "# everythin else = 0\n",
    "\n",
    "mixing_matrix = [[1, -1, 0, 0],# sink 558, no spillover\n",
    "                 [0, 1, 0, 0],# sink 610, spillover from 558\n",
    "                 [0, 0, 1, -1],# sink 687, no spillover\n",
    "                 [0, 0, 0, 1]]# sink 740, spillover from 687\n",
    "\n",
    "picasso = PICASSOnn(mixing_matrix)\n",
    "dataset = picasso.get_dataset(test_image.data)\n",
    "dataset = torch.tensor(dataset/4095, dtype= torch.float32)\n",
    "unmixed = picasso.transform.forward(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f05cb6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2,\n",
       "       1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = np.arange(0,20)/10\n",
    "\n",
    "for a in alpha\n",
    "    mi = mine.MINE()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e1f20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "picasso",
   "language": "python",
   "name": "picasso"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
